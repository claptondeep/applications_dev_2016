# Script:   webpage_getlinks.py
# Desc:     Basic web site info gathering and analysis script. 
#           From a URL gets page content, parsing links out.
# Author:   Matt Muir
# 
import sys, re
import webpage_get

def get_links(page):
    ''' find all hyperlinks on a webpage passed in as input and print '''
    
    link_count = {}
    #links = re.findall(r'http[s]?\:.+(?:\w+)?', page)
    #links.sort()
    for link in re.findall(r'(http[s]?\:.+(?:\w+)?)[\\"](?:[.php]?)', page):
        if link not in link_count:
            link_count[link] = 1
        else:
            link_count[link] += 1
    return link_count

def main():
    # temp testing url argument
    sys.argv.append('http://www.napier.ac.uk/Pages/home.aspx')
    
    # Check args
    if len(sys.argv) != 2:
        print '[-] Usage: webpage_getlinks URL'
        return

    
if __name__ == '__main__':
	main()
